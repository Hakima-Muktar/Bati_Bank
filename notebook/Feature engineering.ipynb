{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05ec0d0a",
   "metadata": {},
   "source": [
    "# import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cd6b615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3157588c",
   "metadata": {},
   "source": [
    "# import data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9c0148f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function load_data at 0x0000026A1ECD3420>\n"
     ]
    }
   ],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "import os\n",
    "module_path = r'C:\\Users\\user\\Desktop\\Project\\Bati_Bank\\src\\data_processing.py'\n",
    "spec = importlib.util.spec_from_file_location(\"data_loader\", module_path)\n",
    "data_loader = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(data_loader)\n",
    "\n",
    "# now you can access your function\n",
    "load_data = data_loader.load_data\n",
    "\n",
    "# test\n",
    "print(load_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99448c79",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5f0583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(r\"C:\\Users\\user\\Desktop\\Project\\Bati_Bank\\data\\raw\\loan.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710922bd",
   "metadata": {},
   "source": [
    "# Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a18d4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>total_transaction_amount</th>\n",
       "      <th>avg_transaction_amount</th>\n",
       "      <th>transaction_count</th>\n",
       "      <th>std_transaction_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CustomerId_1</td>\n",
       "      <td>-10000.0</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CustomerId_10</td>\n",
       "      <td>-10000.0</td>\n",
       "      <td>-10000.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CustomerId_1001</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>6558.963333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CustomerId_1002</td>\n",
       "      <td>4225.0</td>\n",
       "      <td>384.090909</td>\n",
       "      <td>11</td>\n",
       "      <td>560.498966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CustomerId_1003</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3333.333333</td>\n",
       "      <td>6</td>\n",
       "      <td>6030.478146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CustomerId  total_transaction_amount  avg_transaction_amount  \\\n",
       "0     CustomerId_1                  -10000.0           -10000.000000   \n",
       "1    CustomerId_10                  -10000.0           -10000.000000   \n",
       "2  CustomerId_1001                   20000.0             4000.000000   \n",
       "3  CustomerId_1002                    4225.0              384.090909   \n",
       "4  CustomerId_1003                   20000.0             3333.333333   \n",
       "\n",
       "   transaction_count  std_transaction_amount  \n",
       "0                  1                     NaN  \n",
       "1                  1                     NaN  \n",
       "2                  5             6558.963333  \n",
       "3                 11              560.498966  \n",
       "4                  6             6030.478146  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_agg = (\n",
    "    df.groupby(\"CustomerId\")\n",
    "    .agg(\n",
    "        total_transaction_amount=(\"Amount\", \"sum\"),\n",
    "        avg_transaction_amount=(\"Amount\", \"mean\"),\n",
    "       transaction_count=(\"Amount\", \"count\"),\n",
    "        std_transaction_amount=(\"Amount\", \"std\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "customer_agg.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a2e85",
   "metadata": {},
   "source": [
    "# Time-Based Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cd740e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TransactionStartTime\"] = pd.to_datetime(df[\"TransactionStartTime\"])\n",
    "\n",
    "df[\"transaction_hour\"] = df[\"TransactionStartTime\"].dt.hour\n",
    "df[\"transaction_day\"] = df[\"TransactionStartTime\"].dt.day\n",
    "df[\"transaction_month\"] = df[\"TransactionStartTime\"].dt.month\n",
    "df[\"transaction_year\"] = df[\"TransactionStartTime\"].dt.year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb420854",
   "metadata": {},
   "source": [
    "# Merge Aggregate Features Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7931289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(customer_agg, on=\"CustomerId\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef24f35",
   "metadata": {},
   "source": [
    "# Drop Loan_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad7d491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"TransactionId\" in df.columns:\n",
    "    df = df.drop(columns=[\"TransactionId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74c4152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target\n",
    "df[\"FraudResult_Binary\"] = df[\"FraudResult\"].map({\"Y\": 0, \"N\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b3929",
   "metadata": {},
   "source": [
    "# WOE + IV FOR CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea6344d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def woe_iv_categorical(df, feature, target=\"FraudResult\"):\n",
    "    temp = df[[feature, target]].copy()\n",
    "    temp = temp[temp[feature].notna()]\n",
    "    temp[feature] = temp[feature].astype(str)\n",
    "\n",
    "    grouped = temp.groupby(feature)[target].agg([\"count\", \"sum\"])\n",
    "    grouped.columns = [\"total\", \"bad\"]\n",
    "    grouped[\"good\"] = grouped[\"total\"] - grouped[\"bad\"]\n",
    "\n",
    "    grouped[\"good_dist\"] = grouped[\"good\"] / grouped[\"good\"].sum()\n",
    "    grouped[\"bad_dist\"] = grouped[\"bad\"] / grouped[\"bad\"].sum()\n",
    "\n",
    "    # Avoid division by zero\n",
    "    grouped[\"good_dist\"] = grouped[\"good_dist\"].replace(0, 1e-9)\n",
    "    grouped[\"bad_dist\"] = grouped[\"bad_dist\"].replace(0, 1e-9)\n",
    "\n",
    "    grouped[\"WOE\"] = np.log(grouped[\"good_dist\"] / grouped[\"bad_dist\"])\n",
    "    grouped[\"IV\"] = (grouped[\"good_dist\"] - grouped[\"bad_dist\"]) * grouped[\"WOE\"]\n",
    "\n",
    "    return grouped.reset_index(), grouped[\"IV\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79797065",
   "metadata": {},
   "source": [
    "# WOE ENCODING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffbf8d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WOE Table for ProductCategory:\n",
      "      ProductCategory  total  bad   good  good_dist      bad_dist        WOE  \\\n",
      "0             airtime  45027   18  45009   0.471451  9.326425e-02   1.620379   \n",
      "1        data_bundles   1613    0   1613   0.016896  1.000000e-09  16.642560   \n",
      "2  financial_services  45405  161  45244   0.473913  8.341969e-01  -0.565446   \n",
      "3              movies    175    0    175   0.001833  1.000000e-09  14.421495   \n",
      "4               other      2    0      2   0.000021  1.000000e-09   9.949856   \n",
      "5              ticket    216    0    216   0.002263  1.000000e-09  14.631987   \n",
      "6           transport     25    2     23   0.000241  1.036269e-02  -3.761520   \n",
      "7                  tv   1279    0   1279   0.013397  1.000000e-09  16.410543   \n",
      "8        utility_bill   1920   12   1908   0.019986  6.217617e-02  -1.134962   \n",
      "\n",
      "         IV  \n",
      "0  0.612807  \n",
      "1  0.281185  \n",
      "2  0.203721  \n",
      "3  0.026435  \n",
      "4  0.000208  \n",
      "5  0.033105  \n",
      "6  0.038073  \n",
      "7  0.219852  \n",
      "8  0.047885  \n",
      "\n",
      "IV for ProductCategory: 1.4632719561651566\n"
     ]
    }
   ],
   "source": [
    "ProductCategory_table, ProductCategory_iv = woe_iv_categorical(df, \"ProductCategory\")\n",
    "print(\"\\nWOE Table for ProductCategory:\")\n",
    "print(ProductCategory_table)\n",
    "print(\"\\nIV for ProductCategory:\", ProductCategory_iv)\n",
    "\n",
    "# Map to WOE\n",
    "ProductCategory_woe_map = dict(zip(ProductCategory_table[\"ProductCategory\"].astype(str), ProductCategory_table[\"WOE\"]))\n",
    "df[\"ProductCategory_WOE\"] = df[\"ProductCategory\"].astype(str).map(ProductCategory_woe_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea18f8f",
   "metadata": {},
   "source": [
    "# IV FOR NUMERIC VARIABLES (automatic binning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fa8de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "numeric_cols.remove(\"FraudResult\")  # exclude target\n",
    "\n",
    "def iv_numeric(df, feature, target=\"FraudResult\", bins=5):\n",
    "    df2 = df[[feature, target]].copy()\n",
    "    df2[\"bin\"] = pd.qcut(df2[feature], q=bins, duplicates=\"drop\")\n",
    "\n",
    "    grouped = df2.groupby(\"bin\")[target].agg([\"count\", \"sum\"])\n",
    "    grouped.columns = [\"total\", \"bad\"]\n",
    "    grouped[\"good\"] = grouped[\"total\"] - grouped[\"bad\"]\n",
    "\n",
    "    grouped[\"good_dist\"] = grouped[\"good\"] / grouped[\"good\"].sum()\n",
    "    grouped[\"bad_dist\"] = grouped[\"bad\"] / grouped[\"bad\"].sum()\n",
    "\n",
    "    grouped[\"good_dist\"] = grouped[\"good_dist\"].replace(0, 1e-9)\n",
    "    grouped[\"bad_dist\"] = grouped[\"bad_dist\"].replace(0, 1e-9)\n",
    "\n",
    "    grouped[\"WOE\"] = np.log(grouped[\"good_dist\"] / grouped[\"bad_dist\"])\n",
    "    grouped[\"IV\"] = (grouped[\"good_dist\"] - grouped[\"bad_dist\"]) * grouped[\"WOE\"]\n",
    "\n",
    "    return grouped.reset_index(), grouped[\"IV\"].sum()\n",
    "\n",
    "\n",
    "numeric_iv_results = []\n",
    "\n",
    "for col in numeric_cols:\n",
    "    table, iv = iv_numeric(df, col)\n",
    "    numeric_iv_results.append([col, iv])\n",
    "\n",
    "numeric_iv_df = pd.DataFrame(numeric_iv_results, columns=[\"Feature\", \"IV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3284b008",
   "metadata": {},
   "source": [
    "# IV FOR CATEGORICAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5d41eeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "cat_iv_results = []\n",
    "for col in categorical_cols:\n",
    "    table, iv = woe_iv_categorical(df, col)\n",
    "    cat_iv_results.append([col, iv])\n",
    "\n",
    "categorical_iv_df = pd.DataFrame(cat_iv_results, columns=[\"Feature\", \"IV\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886fc07",
   "metadata": {},
   "source": [
    "# COMBINE IV AND SELECT FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9e9324d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Combined IV Ranking ===\n",
      "                     Feature         IV\n",
      "0                    BatchId  24.762054\n",
      "3                 CustomerId  18.731850\n",
      "20    std_transaction_amount  16.626277\n",
      "1                  AccountId  14.754754\n",
      "2             SubscriptionId  14.544861\n",
      "11                     Value  10.112496\n",
      "10                    Amount   9.914119\n",
      "17  total_transaction_amount   9.354279\n",
      "18    avg_transaction_amount   6.893800\n",
      "6                  ProductId   5.017794\n",
      "5                 ProviderId   3.329529\n",
      "7            ProductCategory   1.463272\n",
      "22       ProductCategory_WOE   1.460396\n",
      "8                  ChannelId   1.350916\n",
      "19         transaction_count   0.573731\n",
      "13          transaction_hour   0.101902\n",
      "14           transaction_day   0.095925\n",
      "12           PricingStrategy   0.085529\n",
      "15         transaction_month   0.063391\n",
      "4               CurrencyCode   0.000000\n",
      "9                CountryCode   0.000000\n",
      "16          transaction_year   0.000000\n",
      "21        FraudResult_Binary   0.000000\n",
      "\n",
      "Selected Predictive Features (IV >= 0.02):\n",
      "['BatchId', 'CustomerId', 'std_transaction_amount', 'AccountId', 'SubscriptionId', 'Value', 'Amount', 'total_transaction_amount', 'avg_transaction_amount', 'ProductId', 'ProviderId', 'ProductCategory', 'ProductCategory_WOE', 'ChannelId', 'transaction_count', 'transaction_hour', 'transaction_day', 'PricingStrategy', 'transaction_month']\n"
     ]
    }
   ],
   "source": [
    "combined_iv = pd.concat([categorical_iv_df, numeric_iv_df], ignore_index=True)\n",
    "combined_iv = combined_iv.sort_values(\"IV\", ascending=False)\n",
    "\n",
    "print(\"\\n\\n=== Combined IV Ranking ===\")\n",
    "print(combined_iv)\n",
    "# Keep variables with IV >= 0.02\n",
    "selected_features = combined_iv[combined_iv[\"IV\"] >= 0.02][\"Feature\"].tolist()\n",
    "print(\"\\nSelected Predictive Features (IV >= 0.02):\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ea0a7",
   "metadata": {},
   "source": [
    "# WOE TRANSFORM SELECTED FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "32b2d269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_woe = df.copy()\n",
    "# Categorical WOE\n",
    "for f in selected_features:\n",
    "    if f in categorical_cols:\n",
    "        table, _ = woe_iv_categorical(df, f)\n",
    "        woe_map = dict(zip(table[f].astype(str), table[\"WOE\"]))\n",
    "        df_woe[f + \"_WOE\"] = df[f].astype(str).map(woe_map)\n",
    "\n",
    "# Numeric WOE\n",
    "for f in selected_features:\n",
    "    if f in numeric_cols:\n",
    "        bins = pd.qcut(df[f], q=5, duplicates=\"drop\")\n",
    "        table, _ = iv_numeric(df, f)\n",
    "        woe_map = dict(zip(table[\"bin\"].astype(str), table[\"WOE\"]))\n",
    "        df_woe[f + \"_bin\"] = bins.astype(str)\n",
    "        df_woe[f + \"_WOE\"] = df_woe[f + \"_bin\"].map(woe_map)\n",
    "\n",
    "# Final list of WOE features\n",
    "woe_features = [c for c in df_woe.columns if c.endswith(\"_WOE\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd51f69",
   "metadata": {},
   "source": [
    "# IMPUTE MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ff5542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_woe[woe_features]\n",
    "y = df_woe[\"FraudResult\"]\n",
    "\n",
    "imputer = SimpleImputer(strategy='median')  # works for numeric WOE\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690a74f",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION WITH WOE FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9565f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression AUC Score: 0.6902911668707387\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     28641\n",
      "           1       0.00      0.00      0.00        58\n",
      "\n",
      "    accuracy                           1.00     28699\n",
      "   macro avg       0.50      0.50      0.50     28699\n",
      "weighted avg       1.00      1.00      1.00     28699\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "print(\"\\nLogistic Regression AUC Score:\", auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0b4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
